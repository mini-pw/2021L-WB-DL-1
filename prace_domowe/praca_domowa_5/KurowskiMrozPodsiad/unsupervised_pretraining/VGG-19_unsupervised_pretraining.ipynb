{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('data/x_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "x_test = np.load('data/x_test.npy')\n",
    "y_test = np.load('data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import *\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sklm\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from utils import lossprettifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(3768)\n",
    "\n",
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "\n",
    "#Get TensorFlow session\n",
    "def get_session(): \n",
    "  config = tf.ConfigProto() \n",
    "  config.gpu_options.allow_growth = True \n",
    "  return tf.Session(config=config) \n",
    "  \n",
    "# One hot encoding of labels \n",
    "def dense_to_one_hot(labels_dense,num_clases=4):\n",
    "  return np.eye(num_clases)[labels_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dense_to_one_hot(y_train,num_clases=3)\n",
    "y_valid= dense_to_one_hot(y_valid,num_clases=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Image data generation for the training \n",
    "datagen = ImageDataGenerator(\n",
    "               featurewise_center = False, \n",
    "               samplewise_center = False,  # set each sample mean to 0\n",
    "               featurewise_std_normalization = True,  \n",
    "               samplewise_std_normalization = False)  \n",
    "\n",
    "datagen.fit(x_train) \n",
    "for i in range(len(x_test)):\n",
    "      x_test[i] = datagen.standardize(x_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 2)       56        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 2)       38        \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 2)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 4)       76        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 4)       148       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "block5_up (UpSampling2D)     (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1_dec (Conv2D)    (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2_dec (Conv2D)    (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3_dec (Conv2D)    (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4_dec (Conv2D)    (None, 14, 14, 3)         435       \n",
      "_________________________________________________________________\n",
      "block4_up (UpSampling2D)     (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1_dec (Conv2D)    (None, 28, 28, 16)        448       \n",
      "_________________________________________________________________\n",
      "block4_conv2_dec (Conv2D)    (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3_dec (Conv2D)    (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4_dec (Conv2D)    (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block3_up (UpSampling2D)     (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1_dec (Conv2D)    (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "block3_conv2_dec (Conv2D)    (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3_dec (Conv2D)    (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4_dec (Conv2D)    (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block2_up (UpSampling2D)     (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1_dec (Conv2D)    (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "block2_conv2_dec (Conv2D)    (None, 112, 112, 4)       148       \n",
      "_________________________________________________________________\n",
      "block1_up (UpSampling2D)     (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1_dec (Conv2D)    (None, 224, 224, 2)       74        \n",
      "_________________________________________________________________\n",
      "block1_conv2_dec (Conv2D)    (None, 224, 224, 3)       57        \n",
      "=================================================================\n",
      "Total params: 38,060\n",
      "Trainable params: 38,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CONV BLOCKS\n",
    "\n",
    "input_shape = (224,224,3)\n",
    "model = keras.Sequential()\n",
    "\n",
    "#encoder\n",
    "\n",
    "model.add(layers.Conv2D(2, (3, 3), activation='relu',padding='same',name='block1_conv1',kernel_initializer=\"he_normal\",\n",
    "                       input_shape=input_shape))\n",
    "model.add(layers.Conv2D(2, (3, 3), activation='relu',padding='same',name='block1_conv2',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "model.add(layers.Conv2D(4, (3, 3), activation='relu',padding='same',name='block2_conv1',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(4, (3, 3), activation='relu',padding='same',name='block2_conv2',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu',padding='same',name='block3_conv1',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu',padding='same',name='block3_conv2',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu',padding='same',name='block3_conv3',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu',padding='same',name='block3_conv4',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block4_conv1',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block4_conv2',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block4_conv3',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block4_conv4',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block5_conv1',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block5_conv2',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block5_conv3',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block5_conv4',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
    "\n",
    "#decoder\n",
    "\n",
    "model.add(layers.UpSampling2D((2, 2), name='block5_up'))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block5_conv1_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block5_conv2_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block5_conv3_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(3, (3, 3), activation='sigmoid',padding='same',name='block5_conv4_dec',kernel_initializer=\"he_normal\"))\n",
    "\n",
    "model.add(layers.UpSampling2D((2, 2), name='block4_up'))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block4_conv1_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block4_conv2_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',padding='same',name='block4_conv3_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='sigmoid',padding='same',name='block4_conv4_dec',kernel_initializer=\"he_normal\"))\n",
    "\n",
    "model.add(layers.UpSampling2D((2, 2), name='block3_up'))\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu',padding='same',name='block3_conv1_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu',padding='same',name='block3_conv2_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu',padding='same',name='block3_conv3_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu',padding='same',name='block3_conv4_dec',kernel_initializer=\"he_normal\"))\n",
    "\n",
    "model.add(layers.UpSampling2D((2, 2), name='block2_up'))\n",
    "model.add(layers.Conv2D(4, (3, 3), activation='relu',padding='same',name='block2_conv1_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(4, (3, 3), activation='relu',padding='same',name='block2_conv2_dec',kernel_initializer=\"he_normal\"))\n",
    "\n",
    "model.add(layers.UpSampling2D((2, 2), name='block1_up'))\n",
    "model.add(layers.Conv2D(2, (3, 3), activation='relu',padding='same',name='block1_conv1_dec',kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.Conv2D(3, (3, 3), activation='sigmoid',padding='same',name='block1_conv2_dec',kernel_initializer=\"he_normal\"))\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 52s 2s/step - loss: 19469.6586 - accuracy: 0.9662 - val_loss: 20567.0586 - val_accuracy: 0.9979: 19562.89\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 19412.3076 - accuracy: 0.9980 - val_loss: 21474.5254 - val_accuracy: 0.9962\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 19582.7501 - accuracy: 0.9952 - val_loss: 18750.2305 - val_accuracy: 0.9983\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 19731.7198 - accuracy: 0.9973 - val_loss: 20355.6191 - val_accuracy: 0.9999\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 19683.2388 - accuracy: 0.9979 - val_loss: 19920.3262 - val_accuracy: 0.9926\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 19793.1241 - accuracy: 0.9968 - val_loss: 18261.2441 - val_accuracy: 0.9999\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 19657.6252 - accuracy: 0.9971 - val_loss: 18528.2012 - val_accuracy: 0.9961\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 19796.6247 - accuracy: 0.9978 - val_loss: 21142.3730 - val_accuracy: 0.9983\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 20s 629ms/step - loss: 19625.9500 - accuracy: 0.9990 - val_loss: 22469.6914 - val_accuracy: 0.9979\n",
      "Epoch 10/50\n",
      " 4/32 [==>...........................] - ETA: 40s - loss: 20484.5635 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.141578). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 9s 283ms/step - loss: 19926.6020 - accuracy: 0.9987 - val_loss: 20694.8145 - val_accuracy: 0.9964\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 19766.6697 - accuracy: 0.9972 - val_loss: 19693.1289 - val_accuracy: 0.9979\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 9s 283ms/step - loss: 19721.7274 - accuracy: 0.9991 - val_loss: 19444.5996 - val_accuracy: 0.9981\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 19s 595ms/step - loss: 19965.9119 - accuracy: 0.9966 - val_loss: 19072.5840 - val_accuracy: 0.9980\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 19552.2518 - accuracy: 0.9990 - val_loss: 21487.0918 - val_accuracy: 0.9980\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 19775.4614 - accuracy: 0.9979 - val_loss: 21599.3906 - val_accuracy: 0.9963\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 19407.2423 - accuracy: 0.9971 - val_loss: 19016.4199 - val_accuracy: 0.9982\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 19930.3580 - accuracy: 1.0000 - val_loss: 22268.1406 - val_accuracy: 0.9980\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 19604.4562 - accuracy: 0.9988 - val_loss: 20890.0605 - val_accuracy: 0.9961\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 19854.9122 - accuracy: 0.9988 - val_loss: 19977.7695 - val_accuracy: 0.9981\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 19842.0274 - accuracy: 0.9990 - val_loss: 19072.6211 - val_accuracy: 0.9999\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 19503.2598 - accuracy: 0.9944 - val_loss: 24404.3477 - val_accuracy: 0.9941\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 19789.6855 - accuracy: 0.9981 - val_loss: 20785.3594 - val_accuracy: 0.9999\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 4s 126ms/step - loss: 19721.7762 - accuracy: 0.9989 - val_loss: 18894.3320 - val_accuracy: 0.9926\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 4s 128ms/step - loss: 19411.7857 - accuracy: 0.9990 - val_loss: 19634.3066 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 19999.4680 - accuracy: 0.9952 - val_loss: 20386.6680 - val_accuracy: 0.9962\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 19940.3366 - accuracy: 0.9962 - val_loss: 18065.5723 - val_accuracy: 0.9980\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 19576.1937 - accuracy: 0.9944 - val_loss: 18813.9922 - val_accuracy: 0.9982\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 19780.9733 - accuracy: 0.9970 - val_loss: 18630.0391 - val_accuracy: 0.9999\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 19501.3932 - accuracy: 0.9990 - val_loss: 20901.7363 - val_accuracy: 0.9964\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 19649.8901 - accuracy: 0.9979 - val_loss: 23332.8184 - val_accuracy: 0.9960\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 19741.2568 - accuracy: 0.9980 - val_loss: 18995.2715 - val_accuracy: 0.9980\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 19701.8537 - accuracy: 0.9990 - val_loss: 20402.5527 - val_accuracy: 0.9963\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 19676.2634 - accuracy: 0.9978 - val_loss: 18087.1484 - val_accuracy: 0.9981\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 19788.4770 - accuracy: 0.9980 - val_loss: 19046.5742 - val_accuracy: 0.9980\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 4s 128ms/step - loss: 19739.1024 - accuracy: 0.9995 - val_loss: 21060.2109 - val_accuracy: 0.9964\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 19791.3978 - accuracy: 0.9972 - val_loss: 21098.9082 - val_accuracy: 0.9979\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 19602.5515 - accuracy: 0.9986 - val_loss: 18424.3301 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 19575.0439 - accuracy: 0.9972 - val_loss: 18759.0547 - val_accuracy: 0.9980\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 19841.7142 - accuracy: 0.9971 - val_loss: 20256.9414 - val_accuracy: 0.9942\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 4s 123ms/step - loss: 19785.6406 - accuracy: 0.9959 - val_loss: 18970.9258 - val_accuracy: 0.9980\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 19742.6925 - accuracy: 0.9963 - val_loss: 19470.9199 - val_accuracy: 0.9999\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 19733.3174 - accuracy: 0.9971 - val_loss: 19250.7910 - val_accuracy: 0.9943\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 19744.8494 - accuracy: 0.9957 - val_loss: 22986.2227 - val_accuracy: 0.9982\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 4s 128ms/step - loss: 19847.4595 - accuracy: 0.9998 - val_loss: 18018.8184 - val_accuracy: 0.9980\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 19613.4054 - accuracy: 0.9957 - val_loss: 19648.6992 - val_accuracy: 0.9960\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 19682.5529 - accuracy: 0.9991 - val_loss: 20770.6836 - val_accuracy: 0.9980\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 19618.5922 - accuracy: 0.9980 - val_loss: 20021.5527 - val_accuracy: 0.9983\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 19845.3558 - accuracy: 0.9980 - val_loss: 21787.8184 - val_accuracy: 0.9959\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 19760.5070 - accuracy: 0.9990 - val_loss: 21670.2598 - val_accuracy: 0.9964\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 19699.7476 - accuracy: 0.9971 - val_loss: 19234.7930 - val_accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "#Defining hyperparameters\n",
    "batch_Size = 32\n",
    "steps_Per_Epoch = 32\n",
    "numEpochs = 50\n",
    "\n",
    "#Instantating VGG19 model\n",
    "#model = VGG19((224,224,3),classes=3) #VGG19_dense for revised VGG19, VGG19 for VGG19. Please pay attention to VGG16(), chnage the input shape and class number in VGG.py.\n",
    "\n",
    "#Creating an optimizers\n",
    "adaDelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "#Creating early stopping \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, verbose = 1, mode = 'auto', restore_best_weights = True)       \n",
    "\n",
    "train_generator = datagen.flow(x_train, x_train, batch_size = batch_Size)\n",
    "validation_generator = datagen.flow(x_valid, x_valid, batch_size = batch_Size)\n",
    "\n",
    "# Model training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_Per_Epoch,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 16,\n",
    "    epochs = numEpochs,\n",
    "    shuffle = True, \n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578/1578 [==============================] - 172s 109ms/step\n",
      "Accuracy: 0.9994408488273621\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, x_test, batch_size=batch_Size)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 2)       56        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 2)       38        \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 2)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 4)       76        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 4)       148       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 16)          0         \n",
      "=================================================================\n",
      "Total params: 38,060\n",
      "Trainable params: 38,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "# pruning decoders\n",
    "for i in range(21):\n",
    "    model.pop()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('data/x_train_undersampled.npy')\n",
    "y_train = np.load('data/y_train_undersampled.npy')\n",
    "x_test = np.load('data/x_test_undersampled.npy')\n",
    "y_test = np.load('data/y_test_undersampled.npy')\n",
    "\n",
    "# Preparing training and test sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42)\n",
    "y_train = dense_to_one_hot(y_train,num_clases=3)\n",
    "y_valid= dense_to_one_hot(y_valid,num_clases=3)\n",
    "\n",
    "#Image data generation for the training \n",
    "datagen = ImageDataGenerator(\n",
    "               featurewise_center = False, \n",
    "               samplewise_center = False,  # set each sample mean to 0\n",
    "               featurewise_std_normalization = True,  \n",
    "               samplewise_std_normalization = False)  \n",
    "\n",
    "datagen.fit(x_train) \n",
    "for i in range(len(x_test)):\n",
    "      x_test[i] = datagen.standardize(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 2)       56        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 2)       38        \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 2)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 4)       76        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 4)       148       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 38,060\n",
      "Trainable params: 38,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LABELED TRAINING\n",
    "model.add(layers.Flatten(name='flatten'))\n",
    "model.add(layers.Dense(512, activation='relu', name='fc1'))\n",
    "model.add(layers.Dropout(0.5, name=\"dropout_1\"))\n",
    "model.add(layers.Dense(128, activation='relu', name='fc2'))\n",
    "model.add(Dense(3, activation = \"softmax\", name='predictions'))\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers[:21]: #freezing conv layers\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 3/32 [=>............................] - ETA: 27:18 - loss: 1.1391 - accuracy: 0.2083 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.210013). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 174s 5s/step - loss: 1.0972 - accuracy: 0.3555 - val_loss: 1.1003 - val_accuracy: 0.4770\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.0783 - accuracy: 0.4192 - val_loss: 1.0194 - val_accuracy: 0.3713\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 1.0429 - accuracy: 0.4463 - val_loss: 0.9760 - val_accuracy: 0.5768\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.9728 - accuracy: 0.5322 - val_loss: 0.7524 - val_accuracy: 0.5729\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.9555 - accuracy: 0.5459 - val_loss: 0.7100 - val_accuracy: 0.5828\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.9149 - accuracy: 0.5693 - val_loss: 0.8065 - val_accuracy: 0.6387\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.8672 - accuracy: 0.6084 - val_loss: 0.7199 - val_accuracy: 0.6926\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.8774 - accuracy: 0.6016 - val_loss: 0.7601 - val_accuracy: 0.6986\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.8091 - accuracy: 0.6415 - val_loss: 1.0704 - val_accuracy: 0.6966\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8448 - accuracy: 0.6309 - val_loss: 0.7385 - val_accuracy: 0.6427\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.8155 - accuracy: 0.6464 - val_loss: 0.9472 - val_accuracy: 0.5709\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8579 - accuracy: 0.6074 - val_loss: 0.8997 - val_accuracy: 0.6267\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8014 - accuracy: 0.6436 - val_loss: 0.7403 - val_accuracy: 0.7046\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.8367 - accuracy: 0.6309 - val_loss: 0.8583 - val_accuracy: 0.7265\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8004 - accuracy: 0.6543 - val_loss: 0.5321 - val_accuracy: 0.6347\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8274 - accuracy: 0.6367 - val_loss: 0.8732 - val_accuracy: 0.6926\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8382 - accuracy: 0.6357 - val_loss: 0.9476 - val_accuracy: 0.6846\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.8436 - accuracy: 0.6152 - val_loss: 0.7836 - val_accuracy: 0.6766\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.8121 - accuracy: 0.6621 - val_loss: 0.5607 - val_accuracy: 0.7066\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8329 - accuracy: 0.6436 - val_loss: 0.7480 - val_accuracy: 0.6587\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8320 - accuracy: 0.6425 - val_loss: 0.8009 - val_accuracy: 0.7345\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8734 - accuracy: 0.5947 - val_loss: 0.7720 - val_accuracy: 0.7146\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.8315 - accuracy: 0.6289 - val_loss: 0.6668 - val_accuracy: 0.7325\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.8585 - accuracy: 0.6425 - val_loss: 0.8128 - val_accuracy: 0.7445\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8717 - accuracy: 0.5957 - val_loss: 0.7067 - val_accuracy: 0.6986\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8295 - accuracy: 0.6162 - val_loss: 0.7336 - val_accuracy: 0.7126\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.8526 - accuracy: 0.5957 - val_loss: 0.7599 - val_accuracy: 0.6986\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8200 - accuracy: 0.6221 - val_loss: 0.7517 - val_accuracy: 0.7305\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8864 - accuracy: 0.5975 - val_loss: 0.7642 - val_accuracy: 0.7166\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.8930 - accuracy: 0.5820 - val_loss: 0.8868 - val_accuracy: 0.5689\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9370 - accuracy: 0.5244 - val_loss: 0.9786 - val_accuracy: 0.5230\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.9249 - accuracy: 0.5254 - val_loss: 0.8176 - val_accuracy: 0.7066\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9640 - accuracy: 0.5309 - val_loss: 0.9956 - val_accuracy: 0.5469\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9442 - accuracy: 0.5479 - val_loss: 0.8540 - val_accuracy: 0.6866\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9484 - accuracy: 0.5430 - val_loss: 0.8971 - val_accuracy: 0.6707\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.9260 - accuracy: 0.5635 - val_loss: 0.9231 - val_accuracy: 0.6926\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.8904 - accuracy: 0.5752 - val_loss: 0.8174 - val_accuracy: 0.7006\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9238 - accuracy: 0.5537 - val_loss: 0.9097 - val_accuracy: 0.6287\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9364 - accuracy: 0.5410 - val_loss: 0.9674 - val_accuracy: 0.6727\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.9444 - accuracy: 0.5005 - val_loss: 0.8745 - val_accuracy: 0.5888\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.9133 - accuracy: 0.5518 - val_loss: 0.8560 - val_accuracy: 0.6267\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.9119 - accuracy: 0.5244 - val_loss: 0.8189 - val_accuracy: 0.6906\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.9329 - accuracy: 0.5357 - val_loss: 1.0449 - val_accuracy: 0.7046\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8996 - accuracy: 0.5547 - val_loss: 0.6019 - val_accuracy: 0.7345\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.9432 - accuracy: 0.5234 - val_loss: 0.8317 - val_accuracy: 0.7126\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.9584 - accuracy: 0.5303 - val_loss: 0.9768 - val_accuracy: 0.7006\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9487 - accuracy: 0.5244 - val_loss: 0.8484 - val_accuracy: 0.6567\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.9515 - accuracy: 0.5283 - val_loss: 0.9494 - val_accuracy: 0.6248\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.9469 - accuracy: 0.5113 - val_loss: 0.8003 - val_accuracy: 0.6088\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.8930 - accuracy: 0.5615 - val_loss: 0.8207 - val_accuracy: 0.6108\n"
     ]
    }
   ],
   "source": [
    "batch_Size = 32\n",
    "steps_Per_Epoch = 32\n",
    "numEpochs = 50\n",
    "\n",
    "#Creating an optimizers\n",
    "adaDelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Creating early stopping \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, verbose = 1, mode = 'auto', restore_best_weights = True)       \n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size = batch_Size)\n",
    "validation_generator = datagen.flow(x_valid, y_valid, batch_size = batch_Size)\n",
    "\n",
    "# Model training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_Per_Epoch,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 16,\n",
    "    epochs = numEpochs,\n",
    "    shuffle = True, \n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 | LossA: 1.10(+0.00%) \u001b[0m\t| LossAB: 1.10(+0.00%) \u001b[0m\t\n",
      "Epoch     1 | LossA: \u001b[32m1.08(-1.72%) \u001b[0m\t| LossAB: \u001b[32m1.02(-7.35%) \u001b[0m\t\n",
      "Epoch     2 | LossA: \u001b[32m1.04(-3.28%) \u001b[0m\t| LossAB: \u001b[32m0.98(-4.26%) \u001b[0m\t\n",
      "Epoch     3 | LossA: \u001b[32m0.97(-6.72%) \u001b[0m\t| LossAB: \u001b[32m0.75(-22.91%) \u001b[0m\t\n",
      "Epoch     4 | LossA: \u001b[32m0.96(-1.78%) \u001b[0m\t| LossAB: \u001b[32m0.71(-5.64%) \u001b[0m\t\n",
      "Epoch     5 | LossA: \u001b[32m0.91(-4.25%) \u001b[0m\t| LossAB: \u001b[91m0.81(+13.59%) \u001b[0m\t\n",
      "Epoch     6 | LossA: \u001b[32m0.87(-5.21%) \u001b[0m\t| LossAB: \u001b[32m0.72(-10.73%) \u001b[0m\t\n",
      "Epoch     7 | LossA: \u001b[91m0.88(+1.17%) \u001b[0m\t| LossAB: \u001b[91m0.76(+5.58%) \u001b[0m\t\n",
      "Epoch     8 | LossA: \u001b[32m0.81(-7.85%) \u001b[0m\t| LossAB: \u001b[91m1.07(+40.83%) \u001b[0m\t\n",
      "Epoch     9 | LossA: \u001b[91m0.84(+4.48%) \u001b[0m\t| LossAB: \u001b[32m0.74(-31.01%) \u001b[0m\t\n",
      "Epoch    10 | LossA: \u001b[32m0.82(-3.47%) \u001b[0m\t| LossAB: \u001b[91m0.95(+28.26%) \u001b[0m\t\n",
      "Epoch    11 | LossA: \u001b[91m0.86(+5.20%) \u001b[0m\t| LossAB: \u001b[32m0.90(-5.02%) \u001b[0m\t\n",
      "Epoch    12 | LossA: \u001b[32m0.80(-6.59%) \u001b[0m\t| LossAB: \u001b[32m0.74(-17.71%) \u001b[0m\t\n",
      "Epoch    13 | LossA: \u001b[91m0.84(+4.41%) \u001b[0m\t| LossAB: \u001b[91m0.86(+15.94%) \u001b[0m\t\n",
      "Epoch    14 | LossA: \u001b[32m0.80(-4.34%) \u001b[0m\t| LossAB: \u001b[32m0.53(-38.01%) \u001b[0m\t\n",
      "Epoch    15 | LossA: \u001b[91m0.83(+3.37%) \u001b[0m\t| LossAB: \u001b[91m0.87(+64.12%) \u001b[0m\t\n",
      "Epoch    16 | LossA: \u001b[91m0.84(+1.32%) \u001b[0m\t| LossAB: \u001b[91m0.95(+8.52%) \u001b[0m\t\n",
      "Epoch    17 | LossA: \u001b[91m0.84(+0.62%) \u001b[0m\t| LossAB: \u001b[32m0.78(-17.31%) \u001b[0m\t\n",
      "Epoch    18 | LossA: \u001b[32m0.81(-3.73%) \u001b[0m\t| LossAB: \u001b[32m0.56(-28.44%) \u001b[0m\t\n",
      "Epoch    19 | LossA: \u001b[91m0.83(+2.56%) \u001b[0m\t| LossAB: \u001b[91m0.75(+33.39%) \u001b[0m\t\n",
      "Epoch    20 | LossA: \u001b[32m0.83(-0.08%) \u001b[0m\t| LossAB: \u001b[91m0.80(+7.08%) \u001b[0m\t\n",
      "Epoch    21 | LossA: \u001b[91m0.87(+4.95%) \u001b[0m\t| LossAB: \u001b[32m0.77(-3.61%) \u001b[0m\t\n",
      "Epoch    22 | LossA: \u001b[32m0.83(-4.80%) \u001b[0m\t| LossAB: \u001b[32m0.67(-13.62%) \u001b[0m\t\n",
      "Epoch    23 | LossA: \u001b[91m0.86(+3.27%) \u001b[0m\t| LossAB: \u001b[91m0.81(+21.88%) \u001b[0m\t\n",
      "Epoch    24 | LossA: \u001b[91m0.87(+1.52%) \u001b[0m\t| LossAB: \u001b[32m0.71(-13.05%) \u001b[0m\t\n",
      "Epoch    25 | LossA: \u001b[32m0.83(-4.84%) \u001b[0m\t| LossAB: \u001b[91m0.73(+3.81%) \u001b[0m\t\n",
      "Epoch    26 | LossA: \u001b[91m0.85(+2.78%) \u001b[0m\t| LossAB: \u001b[91m0.76(+3.58%) \u001b[0m\t\n",
      "Epoch    27 | LossA: \u001b[32m0.82(-3.82%) \u001b[0m\t| LossAB: \u001b[32m0.75(-1.08%) \u001b[0m\t\n",
      "Epoch    28 | LossA: \u001b[91m0.89(+8.06%) \u001b[0m\t| LossAB: \u001b[91m0.76(+1.66%) \u001b[0m\t\n",
      "Epoch    29 | LossA: \u001b[91m0.89(+0.78%) \u001b[0m\t| LossAB: \u001b[91m0.89(+16.05%) \u001b[0m\t\n",
      "Epoch    30 | LossA: \u001b[91m0.94(+4.93%) \u001b[0m\t| LossAB: \u001b[91m0.98(+10.35%) \u001b[0m\t\n",
      "Epoch    31 | LossA: \u001b[32m0.92(-1.30%) \u001b[0m\t| LossAB: \u001b[32m0.82(-16.45%) \u001b[0m\t\n",
      "Epoch    32 | LossA: \u001b[91m0.96(+4.27%) \u001b[0m\t| LossAB: \u001b[91m1.00(+21.77%) \u001b[0m\t\n",
      "Epoch    33 | LossA: \u001b[32m0.94(-2.09%) \u001b[0m\t| LossAB: \u001b[32m0.85(-14.23%) \u001b[0m\t\n",
      "Epoch    34 | LossA: \u001b[91m0.95(+0.45%) \u001b[0m\t| LossAB: \u001b[91m0.90(+5.05%) \u001b[0m\t\n",
      "Epoch    35 | LossA: \u001b[32m0.93(-2.36%) \u001b[0m\t| LossAB: \u001b[91m0.92(+2.90%) \u001b[0m\t\n",
      "Epoch    36 | LossA: \u001b[32m0.89(-3.84%) \u001b[0m\t| LossAB: \u001b[32m0.82(-11.45%) \u001b[0m\t\n",
      "Epoch    37 | LossA: \u001b[91m0.92(+3.75%) \u001b[0m\t| LossAB: \u001b[91m0.91(+11.30%) \u001b[0m\t\n",
      "Epoch    38 | LossA: \u001b[91m0.94(+1.36%) \u001b[0m\t| LossAB: \u001b[91m0.97(+6.34%) \u001b[0m\t\n",
      "Epoch    39 | LossA: \u001b[91m0.94(+0.89%) \u001b[0m\t| LossAB: \u001b[32m0.87(-9.60%) \u001b[0m\t\n",
      "Epoch    40 | LossA: \u001b[32m0.91(-3.33%) \u001b[0m\t| LossAB: \u001b[32m0.86(-2.11%) \u001b[0m\t\n",
      "Epoch    41 | LossA: \u001b[32m0.91(-0.15%) \u001b[0m\t| LossAB: \u001b[32m0.82(-4.33%) \u001b[0m\t\n",
      "Epoch    42 | LossA: \u001b[91m0.93(+2.29%) \u001b[0m\t| LossAB: \u001b[91m1.04(+27.59%) \u001b[0m\t\n",
      "Epoch    43 | LossA: \u001b[32m0.90(-3.56%) \u001b[0m\t| LossAB: \u001b[32m0.60(-42.39%) \u001b[0m\t\n",
      "Epoch    44 | LossA: \u001b[91m0.94(+4.85%) \u001b[0m\t| LossAB: \u001b[91m0.83(+38.17%) \u001b[0m\t\n",
      "Epoch    45 | LossA: \u001b[91m0.96(+1.62%) \u001b[0m\t| LossAB: \u001b[91m0.98(+17.44%) \u001b[0m\t\n",
      "Epoch    46 | LossA: \u001b[32m0.95(-1.01%) \u001b[0m\t| LossAB: \u001b[32m0.85(-13.14%) \u001b[0m\t\n",
      "Epoch    47 | LossA: \u001b[91m0.95(+0.30%) \u001b[0m\t| LossAB: \u001b[91m0.95(+11.90%) \u001b[0m\t\n",
      "Epoch    48 | LossA: \u001b[32m0.95(-0.53%) \u001b[0m\t| LossAB: \u001b[32m0.80(-15.71%) \u001b[0m\t\n",
      "300/300 [==============================] - 1s 4ms/step\n",
      "Accuracy: 0.5233333110809326\n"
     ]
    }
   ],
   "source": [
    "y_test_oh = dense_to_one_hot(y_test, num_clases=3)\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#Observing the losses but can be commented out as it's not mandatory \n",
    "reporter = lossprettifier.LossPrettifier(show_percentage=True)\n",
    "\n",
    "for i in range(numEpochs-1):\n",
    "    reporter(epoch=i, LossA = train_loss[i], LossAB = val_loss[i])\n",
    "\n",
    "# Model evaluation \n",
    "score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.10      0.18       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "           2       0.47      0.88      0.61       100\n",
      "\n",
      "    accuracy                           0.52       300\n",
      "   macro avg       0.65      0.52      0.46       300\n",
      "weighted avg       0.65      0.52      0.46       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.reshape(len(y_test), 3)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#Print class-wise classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array(['normal', 'COVID19', 'pneumonia']))\n",
    "disp.plot(cmap='Blues') \n",
    "disp.ax_.get_images()[0].set_clim(0, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbvenv36",
   "language": "python",
   "name": "wbvenv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
